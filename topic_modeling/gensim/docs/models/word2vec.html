<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">




<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta property="description" content="Efficient topic modelling of text semantics in Python." />
    <meta property="og:title" content="gensim: topic modelling for humans" />
    <meta property="og:description" content="Efficient topic modelling in Python" />

    
      <title>gensim: models.word2vec – Deep learning with word2vec</title>

    
  <link rel="stylesheet" href="../_static/css/style.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/jquery.qtip.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/anythingslider.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

    <link rel="shortcut icon" href="../_static/favicon.ico"/>

    <script type="text/javascript">
      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-24066335-1']);
      _gaq.push(['_trackPageview']);

      (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();
    </script>

  </head>

  <body>
    <div id="topwrap">
      
      <div id="top1">
        <div id="left1">
          <h1 class="h1gensim">
            <img src="../_static/images/logo-gensim_compact.png" alt="gensim logo" title="Gensim - topic modelling for humans" />
          </h1>
        </div>

        <div id="middleright">
          <div id="middle1">
            <div id="gensim"><a href="../index.html"><img src="../_static/images/gensim_compact.png" alt="gensim" title="Gensim home" /></a></div>
            <div id="tagline"><img src="../_static/images/tagline_compact.png" alt="gensim tagline" /></div>
          </div>
          <div id="right1">
          </div>
        </div>
      </div>
     

      
      <div id="menu">
        <div id="indentation1">
          <ul class="menubuttons">
            <li class="menubutton"><a href="../index.html">Home</a></li>
            <li class="menubutton"><a href="../tutorial.html">Tutorials</a></li>
            <li class="menubutton"><a href="../install.html">Install</a></li>
            <li class="menubutton"><a href="../support.html">Support</a></li>
            <li class="menubutton"><a href="../apiref.html">API</a></li>
            <li class="menubutton"><a href="../about.html">About</a></li>
          </ul>
        </div>
      </div>
      

      <div class="clearer"></div>
    </div>

    
  <script type="text/javascript">
  var DOCUMENTATION_OPTIONS = {
    URL_ROOT: '../',
    VERSION: '0.8.9',
    COLLAPSE_INDEX: false,
    FILE_SUFFIX: '.html',
    HAS_SOURCE: true
  };
  </script>
    <script type="text/javascript" src="../_static/js/jquery-1.9.1.min.js"></script>
    <script type="text/javascript" src="../_static/js/jquery.qtip.min.js"></script>
    <script type="text/javascript" src="../_static/js/jquery-migrate-1.1.1.min.js"></script>
    <script type="text/javascript" src="../_static/js/jquery.anythingslider.min.js"></script>

    
    <div class="document">
      
        <div id="thinbanner">
          <div id="bodythinbanner">
            <span class="h2gensim">models.word2vec – Deep learning with word2vec</span>
          </div>
        </div>
        <div class="obsah">
          <div class="obsahwrapper">
            
  <div class="section" id="module-gensim.models.word2vec">
<span id="models-word2vec-deep-learning-with-word2vec"></span><h1><tt class="xref py py-mod docutils literal"><span class="pre">models.word2vec</span></tt> &#8211; Deep learning with word2vec<a class="headerlink" href="#module-gensim.models.word2vec" title="Permalink to this headline">¶</a></h1>
<p>Deep learning via word2vec&#8217;s &#8220;hierarchical softmax skip-gram model&#8221; <a class="footnote-reference" href="#id3" id="id1">[1]</a>.</p>
<p>The training algorithm was originally ported from the C package <a class="reference external" href="https://code.google.com/p/word2vec/">https://code.google.com/p/word2vec/</a>
and extended with additional functionality.</p>
<p><strong>Install Cython with `pip install cython` before to use optimized word2vec training</strong> (70x speedup <a class="footnote-reference" href="#id4" id="id2">[2]</a>).</p>
<p>Initialize a model with e.g.:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Word2Vec</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
<p>Persist a model to disk with:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Word2Vec</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>  <span class="c"># you can continue training with the loaded model!</span>
</pre></div>
</div>
<p>The model can also be instantiated from an existing file on disk in the word2vec C format:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Word2Vec</span><span class="o">.</span><span class="n">load_word2vec_format</span><span class="p">(</span><span class="s">&#39;/tmp/vectors.txt&#39;</span><span class="p">,</span> <span class="n">binary</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>  <span class="c"># C text format</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Word2Vec</span><span class="o">.</span><span class="n">load_word2vec_format</span><span class="p">(</span><span class="s">&#39;/tmp/vectors.bin&#39;</span><span class="p">,</span> <span class="n">binary</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>  <span class="c"># C binary format</span>
</pre></div>
</div>
<p>You can perform various syntactic/semantic NLP word tasks with the model. Some of them
are already built-in:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="n">positive</span><span class="o">=</span><span class="p">[</span><span class="s">&#39;woman&#39;</span><span class="p">,</span> <span class="s">&#39;king&#39;</span><span class="p">],</span> <span class="n">negative</span><span class="o">=</span><span class="p">[</span><span class="s">&#39;man&#39;</span><span class="p">])</span>
<span class="go">[(&#39;queen&#39;, 0.50882536), ...]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">doesnt_match</span><span class="p">(</span><span class="s">&quot;breakfast cereal dinner lunch&quot;</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
<span class="go">&#39;cereal&#39;</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">similarity</span><span class="p">(</span><span class="s">&#39;woman&#39;</span><span class="p">,</span> <span class="s">&#39;man&#39;</span><span class="p">)</span>
<span class="go">0.73723527</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="p">[</span><span class="s">&#39;computer&#39;</span><span class="p">]</span>  <span class="c"># raw numpy vector of a word</span>
<span class="go">array([-0.00449447, -0.00310097,  0.02421786, ...], dtype=float32)</span>
</pre></div>
</div>
<p>and so on.</p>
<table class="docutils footnote" frame="void" id="id3" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[1]</a></td><td>Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient Estimation of Word Representations in Vector Space. In Proceedings of Workshop at ICLR, 2013.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id4" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id2">[2]</a></td><td>Optimizing word2vec in gensim, <a class="reference external" href="http://radimrehurek.com/2013/09/word2vec-in-python-part-two-optimizing/">http://radimrehurek.com/2013/09/word2vec-in-python-part-two-optimizing/</a></td></tr>
</tbody>
</table>
<dl class="class">
<dt id="gensim.models.word2vec.BrownCorpus">
<em class="property">class </em><tt class="descclassname">gensim.models.word2vec.</tt><tt class="descname">BrownCorpus</tt><big>(</big><em>dirname</em><big>)</big><a class="headerlink" href="#gensim.models.word2vec.BrownCorpus" title="Permalink to this definition">¶</a></dt>
<dd><p>Iterate over sentences from the Brown corpus (part of NLTK data).</p>
</dd></dl>

<dl class="class">
<dt id="gensim.models.word2vec.Text8Corpus">
<em class="property">class </em><tt class="descclassname">gensim.models.word2vec.</tt><tt class="descname">Text8Corpus</tt><big>(</big><em>fname</em><big>)</big><a class="headerlink" href="#gensim.models.word2vec.Text8Corpus" title="Permalink to this definition">¶</a></dt>
<dd><p>Iterate over sentences from the &#8220;text8&#8221; corpus, unzipped from <a class="reference external" href="http://mattmahoney.net/dc/text8.zip">http://mattmahoney.net/dc/text8.zip</a> .</p>
</dd></dl>

<dl class="class">
<dt id="gensim.models.word2vec.Vocab">
<em class="property">class </em><tt class="descclassname">gensim.models.word2vec.</tt><tt class="descname">Vocab</tt><big>(</big><em>**kwargs</em><big>)</big><a class="headerlink" href="#gensim.models.word2vec.Vocab" title="Permalink to this definition">¶</a></dt>
<dd><p>A single vocabulary item, used internally for constructing binary trees (incl. both word leaves and inner nodes).</p>
</dd></dl>

<dl class="class">
<dt id="gensim.models.word2vec.Word2Vec">
<em class="property">class </em><tt class="descclassname">gensim.models.word2vec.</tt><tt class="descname">Word2Vec</tt><big>(</big><em>sentences=None</em>, <em>size=100</em>, <em>alpha=0.025</em>, <em>window=5</em>, <em>min_count=5</em>, <em>seed=1</em>, <em>workers=1</em>, <em>min_alpha=0.0001</em><big>)</big><a class="headerlink" href="#gensim.models.word2vec.Word2Vec" title="Permalink to this definition">¶</a></dt>
<dd><p>Class for training, using and evaluating neural networks described in <a class="reference external" href="https://code.google.com/p/word2vec/">https://code.google.com/p/word2vec/</a></p>
<p>The model can be stored/loaded via its <cite>save()</cite> and <cite>load()</cite> methods, or stored/loaded in a format
compatible with the original word2vec implementation via <cite>save_word2vec_format()</cite> and <cite>load_word2vec_format()</cite>.</p>
<p>Initialize the model from an iterable of <cite>sentences</cite>. Each sentence is a
list of words (utf8 strings) that will be used for training.</p>
<p>The <cite>sentences</cite> iterable can be simply a list, but for larger corpora,
consider an iterable that streams the sentences directly from disk/network.
See <a class="reference internal" href="#gensim.models.word2vec.BrownCorpus" title="gensim.models.word2vec.BrownCorpus"><tt class="xref py py-class docutils literal"><span class="pre">BrownCorpus</span></tt></a>, <a class="reference internal" href="#gensim.models.word2vec.Text8Corpus" title="gensim.models.word2vec.Text8Corpus"><tt class="xref py py-class docutils literal"><span class="pre">Text8Corpus</span></tt></a> or <tt class="xref py py-class docutils literal"><span class="pre">LineSentence</span></tt> in
this module for such examples.</p>
<p>If you don&#8217;t supply <cite>sentences</cite>, the model is left uninitialized &#8211; use if
you plan to initialize it in some other way.</p>
<p><cite>size</cite> is the dimensionality of the feature vectors.
<cite>window</cite> is the maximum distance between the current and predicted word within a sentence.
<cite>alpha</cite> is the initial learning rate (will linearly drop to zero as training progresses).
<cite>seed</cite> = for the random number generator.
<cite>min_count</cite> = ignore all words with total frequency lower than this.
<cite>workers</cite> = use this many worker threads to train the model (=faster training with multicore machines)</p>
<dl class="method">
<dt id="gensim.models.word2vec.Word2Vec.accuracy">
<tt class="descname">accuracy</tt><big>(</big><em>questions</em>, <em>restrict_vocab=30000</em><big>)</big><a class="headerlink" href="#gensim.models.word2vec.Word2Vec.accuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute accuracy of the model. <cite>questions</cite> is a filename where lines are
4-tuples of words, split into sections by &#8221;: SECTION NAME&#8221; lines.
See <a class="reference external" href="https://code.google.com/p/word2vec/source/browse/trunk/questions-words.txt">https://code.google.com/p/word2vec/source/browse/trunk/questions-words.txt</a> for an example.</p>
<p>The accuracy is reported (=printed to log and returned as a list) for each
section separately, plus there&#8217;s one aggregate summary at the end.</p>
<p>Use <cite>restrict_vocab</cite> to ignore all questions containing a word whose frequency
is not in the top-N most frequent words (default top 30,000).</p>
<p>This method corresponds to the <cite>compute-accuracy</cite> script of the original C word2vec.</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.word2vec.Word2Vec.build_vocab">
<tt class="descname">build_vocab</tt><big>(</big><em>sentences</em><big>)</big><a class="headerlink" href="#gensim.models.word2vec.Word2Vec.build_vocab" title="Permalink to this definition">¶</a></dt>
<dd><p>Build vocabulary from a sequence of sentences (can be a once-only generator stream).
Each sentence must be a list of utf8 strings.</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.word2vec.Word2Vec.create_binary_tree">
<tt class="descname">create_binary_tree</tt><big>(</big><big>)</big><a class="headerlink" href="#gensim.models.word2vec.Word2Vec.create_binary_tree" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a binary Huffman tree using stored vocabulary word counts. Frequent words
will have shorter binary codes. Called internally from <cite>build_vocab()</cite>.</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.word2vec.Word2Vec.doesnt_match">
<tt class="descname">doesnt_match</tt><big>(</big><em>words</em><big>)</big><a class="headerlink" href="#gensim.models.word2vec.Word2Vec.doesnt_match" title="Permalink to this definition">¶</a></dt>
<dd><p>Which word from the given list doesn&#8217;t go with the others?</p>
<p>Example:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">trained_model</span><span class="o">.</span><span class="n">doesnt_match</span><span class="p">(</span><span class="s">&quot;breakfast cereal dinner lunch&quot;</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
<span class="go">&#39;cereal&#39;</span>
</pre></div>
</div>
</dd></dl>

<dl class="classmethod">
<dt id="gensim.models.word2vec.Word2Vec.load">
<em class="property">classmethod </em><tt class="descname">load</tt><big>(</big><em>fname</em><big>)</big><a class="headerlink" href="#gensim.models.word2vec.Word2Vec.load" title="Permalink to this definition">¶</a></dt>
<dd><p>Load a previously saved object from file (also see <cite>save</cite>).</p>
</dd></dl>

<dl class="classmethod">
<dt id="gensim.models.word2vec.Word2Vec.load_word2vec_format">
<em class="property">classmethod </em><tt class="descname">load_word2vec_format</tt><big>(</big><em>fname</em>, <em>binary=False</em><big>)</big><a class="headerlink" href="#gensim.models.word2vec.Word2Vec.load_word2vec_format" title="Permalink to this definition">¶</a></dt>
<dd><p>Load the input-hidden weight matrix from the original C word2vec-tool format.</p>
<p>Note that the information loaded is incomplete (the binary tree is missing),
so while you can query for word similarity etc., you cannot continue training
with a model loaded this way.</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.word2vec.Word2Vec.most_similar">
<tt class="descname">most_similar</tt><big>(</big><em>positive=</em><span class="optional">[</span><span class="optional">]</span>, <em>negative=</em><span class="optional">[</span><span class="optional">]</span>, <em>topn=10</em><big>)</big><a class="headerlink" href="#gensim.models.word2vec.Word2Vec.most_similar" title="Permalink to this definition">¶</a></dt>
<dd><p>Find the top-N most similar words. Positive words contribute positively towards the
similarity, negative words negatively.</p>
<p>This method computes cosine similarity between a simple mean of the projection
weight vectors of the given words, and corresponds to the <cite>word-analogy</cite> and
<cite>distance</cite> scripts in the original word2vec implementation.</p>
<p>Example:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">trained_model</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="n">positive</span><span class="o">=</span><span class="p">[</span><span class="s">&#39;woman&#39;</span><span class="p">,</span> <span class="s">&#39;king&#39;</span><span class="p">],</span> <span class="n">negative</span><span class="o">=</span><span class="p">[</span><span class="s">&#39;man&#39;</span><span class="p">])</span>
<span class="go">[(&#39;queen&#39;, 0.50882536), ...]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="gensim.models.word2vec.Word2Vec.reset_weights">
<tt class="descname">reset_weights</tt><big>(</big><big>)</big><a class="headerlink" href="#gensim.models.word2vec.Word2Vec.reset_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset all projection weights to an initial (untrained) state, but keep the existing vocabulary.</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.word2vec.Word2Vec.save">
<tt class="descname">save</tt><big>(</big><em>fname</em><big>)</big><a class="headerlink" href="#gensim.models.word2vec.Word2Vec.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Save the object to file via pickling (also see <cite>load</cite>).</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.word2vec.Word2Vec.save_word2vec_format">
<tt class="descname">save_word2vec_format</tt><big>(</big><em>fname</em>, <em>binary=False</em><big>)</big><a class="headerlink" href="#gensim.models.word2vec.Word2Vec.save_word2vec_format" title="Permalink to this definition">¶</a></dt>
<dd><p>Store the input-hidden weight matrix in the same format used by the original
C word2vec-tool, for compatibility.</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.word2vec.Word2Vec.similarity">
<tt class="descname">similarity</tt><big>(</big><em>w1</em>, <em>w2</em><big>)</big><a class="headerlink" href="#gensim.models.word2vec.Word2Vec.similarity" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute cosine similarity between two words.</p>
<p>Example:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">trained_model</span><span class="o">.</span><span class="n">similarity</span><span class="p">(</span><span class="s">&#39;woman&#39;</span><span class="p">,</span> <span class="s">&#39;man&#39;</span><span class="p">)</span>
<span class="go">0.73723527</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">trained_model</span><span class="o">.</span><span class="n">similarity</span><span class="p">(</span><span class="s">&#39;woman&#39;</span><span class="p">,</span> <span class="s">&#39;woman&#39;</span><span class="p">)</span>
<span class="go">1.0</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="gensim.models.word2vec.Word2Vec.train">
<tt class="descname">train</tt><big>(</big><em>sentences</em>, <em>total_words=None</em>, <em>word_count=0</em>, <em>chunksize=100</em><big>)</big><a class="headerlink" href="#gensim.models.word2vec.Word2Vec.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the model&#8217;s neural weights from a sequence of sentences (can be a once-only generator stream).
Each sentence must be a list of utf8 strings.</p>
</dd></dl>

</dd></dl>

</div>


          </div>
        </div>
      

      <div class="clearer"></div>
    </div>
    

    
    <div id="footer">
      <div id="footerwrapper">
        <div id="footerleft">
          <img src="../_static/images/logo-gensim.png" class="smallerlogo" alt="smaller gensim logo" />
          <a href="../index.html"><img src="../_static/images/gensim-footer.png" alt="gensim footer image" title="Gensim home" /></a>
          <div class="copyright">
            &copy; Copyright 2009-2013, <a href="mailto:radimrehurek@seznam.cz" style="color:white"> Radim Řehůřek</a>
            <br />
              Last updated on Dec 26, 2013.
          </div>
        </div>

        <div id="footermiddleright">
          <div id="footermiddle">
            <ul class="navigation">
              <li><a href="../index.html">
                Home
              </a></li>
              <li>|</li>
              <li><a href="../tutorial.html">
                Tutorials
              </a></li>
              <li>|</li>
              <li><a href="../install.html">
                Install
              </a></li>
              <li>|</li>
              <li><a href="../support.html">
                Support
              </a></li>
              <li>|</li>
              <li><a href="../apiref.html">
                API
              </a></li>
              <li>|</li>
              <li><a href="../about.html">
                About
              </a></li>
            </ul>

            <div class="tweetodsazeni">
              <div class="tweet">
                <a href="https://twitter.com/radimrehurek" target="_blank" style="color: white">Tweet @RadimRehurek</a>
              </div>
            </div>

          </div>

          <div id="footerright">
            <div class="footernadpis">
              Support:
            </div>
            <div class="googlegroupsodsazeni">
              <a href="https://groups.google.com/group/gensim" class="googlegroups">
                Join the gensim discussion group
              </a>

              <form action="http://groups.google.com/group/gensim/boxsubscribe">
                <input type="text" name="email" placeholder="your@email.com" size="28" />
                <input type="submit" name="sub" value="Subscribe" />
              </form>

            </div>

            <div class="addthis_toolbox addthis_default_style addthis_32x32_style"
                addthis:title="#gensim"
                addthis:description="Efficient Topic Modelling in Python"
                style="margin:20px 0 0 0">
              <a class="addthis_button_preferred_1"></a>
              <a class="addthis_button_preferred_2"></a>
              <a class="addthis_button_preferred_3"></a>
              <a class="addthis_button_preferred_4"></a>
              <a class="addthis_button_compact"></a>
              <a class="addthis_counter addthis_bubble_style"></a>
            </div>
          </div>

        </div>
      </div>
    </div>
    

    <script type="text/javascript">
      (function() {
      var at = document.createElement('script'); at.type = 'text/javascript'; at.async = true;
      at.src = ('https:' == document.location.protocol ? 'https://' : 'http://') + 's7.addthis.com/js/250/addthis_widget.js#pubid=ra-4d738b9b1d31ccbd';
      var sat = document.getElementsByTagName('script')[0]; sat.parentNode.insertBefore(at, sat);
      })();
    </script>

  </body>
</html>